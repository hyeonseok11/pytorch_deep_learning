{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset 상속\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    # 데이터셋의 전처리를 해주는 부분\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "        \n",
    "    # 데이터셋의 길이. 즉, 총 데이터의 개수를 리턴\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 cost: 4.903973\n",
      "Epoch    0/20 Batch 2/3 cost: 3.914548\n",
      "Epoch    0/20 Batch 3/3 cost: 1.699941\n",
      "Epoch    1/20 Batch 1/3 cost: 4.627671\n",
      "Epoch    1/20 Batch 2/3 cost: 3.114462\n",
      "Epoch    1/20 Batch 3/3 cost: 0.066012\n",
      "Epoch    2/20 Batch 1/3 cost: 1.960549\n",
      "Epoch    2/20 Batch 2/3 cost: 4.447224\n",
      "Epoch    2/20 Batch 3/3 cost: 4.093805\n",
      "Epoch    3/20 Batch 1/3 cost: 3.028887\n",
      "Epoch    3/20 Batch 2/3 cost: 3.868366\n",
      "Epoch    3/20 Batch 3/3 cost: 3.847969\n",
      "Epoch    4/20 Batch 1/3 cost: 1.564044\n",
      "Epoch    4/20 Batch 2/3 cost: 4.158138\n",
      "Epoch    4/20 Batch 3/3 cost: 3.618157\n",
      "Epoch    5/20 Batch 1/3 cost: 2.704309\n",
      "Epoch    5/20 Batch 2/3 cost: 3.000708\n",
      "Epoch    5/20 Batch 3/3 cost: 4.073947\n",
      "Epoch    6/20 Batch 1/3 cost: 4.472549\n",
      "Epoch    6/20 Batch 2/3 cost: 2.432489\n",
      "Epoch    6/20 Batch 3/3 cost: 2.286124\n",
      "Epoch    7/20 Batch 1/3 cost: 3.098393\n",
      "Epoch    7/20 Batch 2/3 cost: 2.472535\n",
      "Epoch    7/20 Batch 3/3 cost: 7.850445\n",
      "Epoch    8/20 Batch 1/3 cost: 3.420963\n",
      "Epoch    8/20 Batch 2/3 cost: 3.141891\n",
      "Epoch    8/20 Batch 3/3 cost: 3.748823\n",
      "Epoch    9/20 Batch 1/3 cost: 3.248796\n",
      "Epoch    9/20 Batch 2/3 cost: 3.808130\n",
      "Epoch    9/20 Batch 3/3 cost: 3.747405\n",
      "Epoch   10/20 Batch 1/3 cost: 3.348362\n",
      "Epoch   10/20 Batch 2/3 cost: 1.584696\n",
      "Epoch   10/20 Batch 3/3 cost: 5.726037\n",
      "Epoch   11/20 Batch 1/3 cost: 3.779587\n",
      "Epoch   11/20 Batch 2/3 cost: 0.665982\n",
      "Epoch   11/20 Batch 3/3 cost: 6.682733\n",
      "Epoch   12/20 Batch 1/3 cost: 3.244015\n",
      "Epoch   12/20 Batch 2/3 cost: 3.717885\n",
      "Epoch   12/20 Batch 3/3 cost: 0.697466\n",
      "Epoch   13/20 Batch 1/3 cost: 2.122122\n",
      "Epoch   13/20 Batch 2/3 cost: 2.892767\n",
      "Epoch   13/20 Batch 3/3 cost: 4.358778\n",
      "Epoch   14/20 Batch 1/3 cost: 6.341309\n",
      "Epoch   14/20 Batch 2/3 cost: 4.442363\n",
      "Epoch   14/20 Batch 3/3 cost: 0.001531\n",
      "Epoch   15/20 Batch 1/3 cost: 2.901843\n",
      "Epoch   15/20 Batch 2/3 cost: 3.711894\n",
      "Epoch   15/20 Batch 3/3 cost: 2.313754\n",
      "Epoch   16/20 Batch 1/3 cost: 0.336447\n",
      "Epoch   16/20 Batch 2/3 cost: 4.004616\n",
      "Epoch   16/20 Batch 3/3 cost: 6.346192\n",
      "Epoch   17/20 Batch 1/3 cost: 5.311671\n",
      "Epoch   17/20 Batch 2/3 cost: 2.639923\n",
      "Epoch   17/20 Batch 3/3 cost: 3.177093\n",
      "Epoch   18/20 Batch 1/3 cost: 3.240993\n",
      "Epoch   18/20 Batch 2/3 cost: 3.931090\n",
      "Epoch   18/20 Batch 3/3 cost: 0.753841\n",
      "Epoch   19/20 Batch 1/3 cost: 1.705782\n",
      "Epoch   19/20 Batch 2/3 cost: 3.559587\n",
      "Epoch   19/20 Batch 3/3 cost: 4.217290\n",
      "Epoch   20/20 Batch 1/3 cost: 3.773368\n",
      "Epoch   20/20 Batch 2/3 cost: 1.714504\n",
      "Epoch   20/20 Batch 3/3 cost: 3.738490\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        \n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        pred = model(x_train)\n",
    "        cost = F.mse_loss(pred, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch:4d}/{epochs} Batch {batch_idx + 1}/{len(dataloader)} cost: {cost.item():.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_book",
   "language": "python",
   "name": "pt_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
